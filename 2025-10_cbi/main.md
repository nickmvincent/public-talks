---
marp: true
theme: default
paginate: true
size: 16:9
title: "Collective Bargaining in the Information Economy"
description: "How collective bargaining for information can counter AI-driven power concentration"
class: lead
---

# Collective Bargaining in the Information Economy
### Addressing AI-driven power concentration

Nicholas Vincent (SFU) · Matthew Prewitt (RadicalxChange) · Hanlin Li (UT Austin)

---

## Core Idea

Collective Bargaining in the Information Economy (CBI) lets people who create* or steward* information negotiate fair terms with AI builders.

Without CBI, (we think that) AI will deepen familiar information market failures:
- Price goes to zero (no leverage for knowledge work / all work)
- Capital and decision-making consolidate in a handful of firms
- Shared knowledge ecosystems erode

CBI is not a cure-all, but it gives communities a realistic lever for accountability in the near term.

(*Important todo in future is further customizing for creators vs. stewards)


---

## Why This Matters

- Information can be copied at almost no cost, so prices tend to collapse.  
- Those who aggregate and control data capture most of its value.  
- AI magnifies that imbalance and weakens incentives to produce new knowledge.  
- Traditional countermeasures—IP law, secrecy, public funding—are showing their limits.

We need coordinated social+legal+technical interventions to rebalance the market for information.

---

## What Is Collective Bargaining for Information?

Bargaining between:
- Data intermediaries or guilds representing large groups of information producers  
- AI operators using data to build models  

Typical topics include:
- Terms of data use  
- Compensation mechanisms  
- Limits on downstream applications  
- Reporting and transparency requirements

---

## The Problem: Market Failure for Information

Information goods rarely find efficient prices.  
Open data and permissive scraping let AI developers capture value while creators receive little or nothing.  
Market power concentrates in incumbent tech platforms.  
Incentives for journalism, research, and creative work shrink.

---

## AI Accelerates These Failures

AI reduces informational friction by:
- Making it easier to extract value from public data  
- Weakening the practical force of IP protections  
- Raising returns to capital more than returns to creativity

The result is tighter concentration of financial, informational, and decision power.

---

## Consequences of Power Concentration

(Worth stating, we think)

Political and moral risks:
- Democratic instability  
- Loss of creative and moral diversity  
- Feedback loops that entrench the most powerful actors
  
Technical and economic risks:
- Collapse of high-quality "data ecosystems"  
- Reduced AI reliability and diversity  

---

## Why CBI Is a "Safety" Strategy

CBI:
- Distributes control over informational resources  
- Creates accountability through trusted intermediaries  
- Enables auditing and model evaluation with privately held data  
- Encourages data-centric investment instead of pure compute escalation  

---

## Technical Foundations: Data Counterfactuals

Various research efforts give us tools to ask how models would perform under different data histories:
- Data value estimation (influence functions, data Shapley, new stuff: metagradients, small value estimation models) prices individual or pooled contributions  
- Data scaling and selection studies show performance trajectories as datasets grow or shift  
- Data poisoning work probes worst-case impacts when inputs are manipulated  
- Algorithmic collective action explores how groups can coordinate data supply, gain leverage  

Together, these methods map the space of "what if we had different data?" scenarios that matter to bargaining.

---

## Another key connection: 

data valuation <> evaluation more generally <> humanities approach to close reading / critical evaluation

(data is most upstream; can talk briefly on this as well?)

---

## Why This Matters for CBI

- Value estimation lets creators and stewards quantify their marginal contribution  
- Scaling analyses highlight when new data types or communities unlock significant gains  
- Poisoning resistance research underscores the need for negotiated quality and safety commitments  
- Collective action theory shows how shared tools can transform individual contributions into bargaining power  

As these techniques mature, they equip intermediaries with credible evidence to negotiate terms grounded in measurable impact.

---

## Building the Coalition

We propose an inclusive, cross-disciplinary effort connecting:

- Researchers  
- Information producers  
- AI developers  
- Policymakers  
- Civil society organizations 

(Everybody we can get on board!)

Goal: align incentives for sustainable, pluralistic AI development.

---

## Actions for Stakeholders

| Stakeholder | Action |
|--------------|---------|
| Information industries | Form joint ventures, negotiate terms, and pause un-negotiated training access |
| Regulators | Offer antitrust safe harbors for collective bargaining |
| ML researchers | Advance interpretability and data valuation methods |
| HCI designers | Build usable interfaces for data control |
| AI safety community | Treat CBI as part of power-balancing safety work |
| Tech companies | Engage with CBI to earn trust and improve data quality |

---

## Complementary Approaches

Open AI ecosystems can spread access but do not fix incentive failures.  
Top-down regulation is necessary yet insufficient.  
CBI adds a negotiation layer that connects incentives with accountability.

---

## The Vision

A healthy information economy rewards creators, keeps AI systems accountable, and distributes power more evenly.

Collective bargaining for information is one step toward that goal.

---

## Discussion / FAQ

- Tactics for coalition building?
- Is this the right strategy?
- Big weaknesses?
